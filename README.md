# FNN_Work_By_Liu
 本项目是《图像合成技术》课程作业，编码作者是MRL Liu。

#### 主要内容：

（1）从零构建一个基础的参数化的全连接神经网络（不使用人工智能算法库）。

（2）使用该网络进行一个分类实验。

（3）使用该网络进行一个回归实验。

#### 主要亮点：

（1）本项目进行了7个版本的神经网络的迭代，每个版本层层推进，适合初学者。

7个迭代的神经网络放在项目中的process文件夹中，其中各个文件的作用：

| 实现模块      | 简要工作描述                                               | 详细描述                                                     |
| ------------- | ---------------------------------------------------------- | ------------------------------------------------------------ |
| network_v1.py | 从神经元层面利用矩阵向量运算实现了一个2*2*1的固定结构的FNN | 激活函数为Sigmoid，损失函数为MSE（均方误差），优化算法为GD（梯度下降），梯度计算算法为BP（反向传播算法），网络初始化方式为高斯分布中随机采样，无正则化处理等 |
| network_v2.py | 实现参数化FNN的设计与实现                                  | 实现了自定义任意结构的参数化（shape_size）神经网络           |
| network_v3.py | 升级优化算法为SGD                                          | 将优化算法从普通梯度下降（GD），升级到了随机小批量梯度下降（SGD），并进行了对比实验。 |
| network_v4.py | 添加了L2正则化操作                                         | 为梯度计算的BP算法添加了L2正则化操作，进行了过拟合的相关实验。 |
| network_v5.py | 进行网络参数初始化的优化工作，参数的保存与保留             | 将网络的权重参数初始化从随机采样过渡到生成Xavier初始化，并进行对比实验。 |
| network_v6.py | 将损失函数替换为交叉熵函数                                 | 损失函数从均方误差变为交叉熵函数，并进行对比实验，并且添加提前终止机制。 |
| network_v7.py | 实现初始化方式、损失函数的参数化，优化损失和正确率的检测   | 网络初始化方式参数化，提供随机初始化、Xavier初始化、导入存储参数等多种方式；损失函数参数化，可以选择MSE损失函数、交叉熵损失函数； |

（2）每份代码都有较为详细的注释

（3）作者的博客之后会推出该项目的迭代过程，有兴趣可移步https://blog.csdn.net/qq_41959920